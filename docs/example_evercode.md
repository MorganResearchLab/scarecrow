<img style="float:right;width:100px;" src="../img/scarecrow.png" alt="scarecrow"/>

[Back to root](../README.md)

# Example: Parse Evercode WTv2

<picture>
  <source media="(prefers-color-scheme: dark)" srcset="../img/parse_dark_v2.svg">
  <img alt="Parse Evercode WTv2 library structure" src="../img/parse_light_v2.svg">
</picture>

Library structure

---

### Prep

Stay organised - create a folder for the project to keep things tidy.

```bash
PROJECT=./scarecrow/examples/Parse
mkdir -p ${PROJECT}
```

Download Evercode WTv2 data from NCBI SRA accession:[SRR28867558](https://www.ncbi.nlm.nih.gov/sra/?term=SRR28867558).

```bash
mkdir -p ${PROJECT}/fastq
ACC=SRR28867558
#sbatch ./scarecrow/scripts/fastq-dump.sh --out ${PROJECT}/fastq --acc ${ACC}
prefetch --output-directory ${PROJECT}/fastq ${ACC}
fasterq-dump ${PROJECT}/fastq/${ACC} -e 2 --split-files --include-technical --force --outdir ${PROJECT}/fastq
gzip ${PROJECT}/fastq/${ACC}_1.fastq # Index
gzip ${PROJECT}/fastq/${ACC}_2.fastq # cDNA sequences
gzip ${PROJECT}/fastq/${ACC}_3.fastq # Barcodes and UMI
```


### 1. Identify barcode seeds

This step requires barcode whitelists associated with the assay being used. Parse Bioscience customers can access the whitelists for the different assays by downloading their splitpipe pipeline. The whitelists are csv files in a barcodes directory (e.g. ./software/ParseBiosciences-Pipeline.1.4.1/splitpipe/barcodes/barcode_data_v1.csv). We only require the barcode sequence for scarecrow, so this needs cutting from the file (i.e. `cut -d',' -f2 barcode_data_v1.csv | sed '1d' > barcode_data_v1.txt`). Once the whitelists are generated, they can be defined as colon-delimited strings (`<barcode index>:<whitelist name>:<whitelist file>`) in a bash array for later use. For convenience, we have provided in the `scarecrow` repo the below [barcode files](../barcodes/Parse)

```bash
BARCODES=(BC1:n99_v5:${PROJECT}/barcode_whitelists/bc_data_n99_v5.txt
          BC2:v1:${PROJECT}/barcode_whitelists/bc_data_v1.txt
          BC3:v1:${PROJECT}/barcode_whitelists/bc_data_v1.txt)
```

We can now run `scarecrow seed` to process each barcode whitelist. The below example is for a SLURM HPC, but will work on a standard PC by omitting the `sbatch` line. It randomly samples 10k reads from the first 100k in the FASTQ files and records the start positions of barcodes, their orientation, nucleotide frequencies per position, and conserved sequence runs.

```bash
mkdir -p ${PROJECT}/barcode_profiles
FASTQS=(${PROJECT}/fastq/*.fastq.gz)
for BARCODE in ${BARCODES[@]}
do
    scarecrow seed \
        --num_reads 10000 \
        --upper_read_count 100000 \
        --fastqs ${FASTQS[@]} \
        --barcodes ${BARCODE} \
        --out ${PROJECT}/barcode_profiles/barcodes.${BARCODE%%:*}.csv
done
```

The above example uses the default set-based barcode matching method. The alternative is to the the trie-based method which is better suited to large barcode whitelists.

```bash
mkdir -p ${PROJECT}/trie/barcode_profiles
FASTQS=(${PROJECT}/fastq/*.fastq.gz)
for BARCODE in ${BARCODES[@]}
do
    scarecrow seed \
        --num_reads 10000 \
        --upper_read_count 100000 \
        --fastqs ${FASTQS[@]} \
        --barcodes ${BARCODE} \
        --pickle ${PROJECT}/trie/barcodes.${BARCODE%%:*}.pkl.gz \
        --kmer_length 3 \
        --out ${PROJECT}/trie/barcode_profiles/barcodes.${BARCODE%%:*}.csv
done
```


### 2. Harvest barcode profiles

The barcode profiles generated by `scarecrow seed` are gathered with `scarecrow harvest` to identify the likely barcode index positions. The `--barcode_count` parameter specifies the number of barcodes to return for **each** barcode index, and should typically be set to `1` unless debugging. The `--min_distance` parameter sets the minimum distance required between the end and start positions of two barcodes. The `--conserved` parameter enables the masking of conserved sequence regions - for instance barcode linker sequences, to prevent barcode positions falling within these regions.

```bash
BARCODE_FILES=(${PROJECT}/barcode_profiles/barcodes.*.csv)
scarecrow harvest \
    ${BARCODE_FILES[@]} \
    --barcode_count 1 \
    --min_distance 10 \
    --conserved ${PROJECT}/barcode_profiles/barcodes.${BARCODES[0]%%:*}_conserved.tsv \
    --out ${PROJECT}/barcode_profiles/barcode_positions.csv
```


Problem-solve inconsistencies between set-based and trie-based methods:

```bash
./scripts/compare_barcodes.py \
    --file1 ${PROJECT}/barcode_profiles/barcodes.BC1.csv \
    --file2 ${PROJECT}/trie/barcode_profiles/barcodes.BC1.csv \
    --output ${PROJECT}/barcodes.BC1.differences
```
file_index      file    read_name       seqlen  barcode_whitelist       barcode orientation     start   end     mismatches      source
1       SRR28867558_2.fastq.gz  SRR28867558.10043       74      BC1:n99_v5      TCTCATGC        reverse 24      31      0       file1
1       SRR28867558_2.fastq.gz  SRR28867558.10043       74      BC1:n99_v5      TCTCATGC        reverse 44      51      0       file2

GCATGAGA
GCTTGGTTTTATGTTTTAGGTTG[GCATGAGA]CATCAGTCAAATACATTAAATACATTGGTTTGGTCCAGGAAGG

Both the set- and trie-based methods are processed in the same manner with `harvest`. However, to illustrate that the same barcode profiels are generated, we can repeat the above on the trie-based method outputs from `seed`.

```bash
BARCODE_FILES=(${PROJECT}/trie/barcode_profiles/barcodes.*.csv)
scarecrow harvest \
    ${BARCODE_FILES[@]} \
    --barcode_count 1 \
    --min_distance 10 \
    --conserved ${PROJECT}/trie/barcode_profiles/barcodes.${BARCODES[0]%%:*}_conserved.tsv \
    --out ${PROJECT}/trie/barcode_profiles/barcode_positions.csv
```

The plots generated by `harvest` indicates that no barcode matches were found on read 1 (SRR28867558_1.fastq.gz), virtually no barcode matches were found on read 2 (SRR28867558_2.fastq.gz), regardless of barcode orientation, while matches were found on read 3 (SRR28867558_3.fastq.gz) in both orientations. The majority of reads returned matches at positions 11, 49, and 79 in forward orientation, which correspond with the positions of the 3 barcodes expected of the assay. An additional peak was identified in a conserved region (highlighted in red) that corresponds with one of the linker sequences of the assay. As this peak falls within a conserved region it is ignored.

<br>
<table>
  <tr>
    <td><img src="../img/parse_index_1_forward.png" alt="Barcode profiles for FASTQ index 1, forward orientation"></td>
    <td><img src="../img/parse_index_1_reverse.png" alt="Barcode profiles for FASTQ index 1, reverse orientation"></td>
  </tr>
  <tr>
    <td><img src="../img/parse_index_2_forward.png" alt="Barcode profiles for FASTQ index 2, forward orientation"></td>
    <td><img src="../img/parse_index_2_reverse.png" alt="Barcode profiles for FASTQ index 2, reverse orientation"></td>
  </tr>
</table>
<br>

The regions for the three barcodes (one per whitelist) selected by the `harvest` are highlighted in blue. These are recorded in the barcode_positions.csv file. Note, file_index is 0-based.

```bash
barcode_whitelist,file_index,file,orientation,start,end,read_count,read_fraction
BC2:v1,2,SRR28867558_3.fastq.gz,forward,11,18,8850,0.93
BC3:v1,2,SRR28867558_3.fastq.gz,forward,49,56,8327,0.87
BC1:n99_v5,2,SRR28867558_3.fastq.gz,forward,79,86,7447,0.8
```


### 3. Reap sequence data ###

Now that the barcode positions have been characterised we can extract the target sequence with `scarecrow reap`. This will also record barcode metadata (sequence, qualities, corrected sequence, positions, mismatches) and UMI data (sequence, quailties). The output can be either SAM format (default) or FASTQ. The range to `--extract` includes the read index (e.g. `1` or `2`) followed by the positional range, and `--umi` follows the same format to indicate where the UMI sequence is. The `--jitter` parameter indicates the number of flanking bases to extend the barcode start position by when looking for a match. The `--mismatch` parameter indicates the maximum number of mismatches permitted when matching the barcode against a whitelist - also known as the edit distance. The `--base_quality` parameter base quality threshold, below which bases are masked as `N`, this step occurs before barcode matching and can significantly reduce the number of valid barcodes if set too high. For a fair comparison with the Parse splitpipe workflow we do not apply any base quality masking in this instance.

We're running this on a SLURM HPC and it takes around an hour using 16 cores.

```bash
THREADS=16
JITTER=1
MISMATCH=2
FASTQS=(${PROJECT}/fastq/*.fastq.gz)
OUT=$(basename ${FASTQS[0]%.fastq*})
mkdir -p ${PROJECT}/extracted/J${JITTER}M${MISMATCH}
sbatch -p uoa-compute --ntasks 1 --cpus-per-task ${THREADS} --mem 16G --time=12:00:00 -o reap.%j.out -e reap.%j.err \
    scarecrow reap \
        --threads ${THREADS} \
        --batch_size 20000 \
        --fastqs ${FASTQS[@]} \
        --barcode_positions ${PROJECT}/barcode_profiles/barcode_positions.csv \
        --barcodes ${BARCODES[@]} \
        --extract 2:1-74 --umi 3:1-10 \
        --jitter ${JITTER} \
        --mismatch ${MISMATCH} \
        --out ${PROJECT}/extracted/J${JITTER}M${MISMATCH}/${OUT} \
        --out_fastq
```


Check that the read count in the resulting FASTQ file is equal to that of one of the input FASTQ files. This is a basic sanity check to ensure that nothing unexpected happened whilst running `scarecrow` on the HPC that might have resulted in some I/O issues. Here is an example of counting reads using `seqtk` and `awk` on non-interleaved and interleaved FASTQ files.

```bash
# A non-interleaved input FASTQ file
seqtk seq ${FASTQS[0]} | awk '/^@/ {c++} END {print c}'
# Interleaved scarecrow FASTQ file
seqtk seq ${PROJECT}/extracted/J${JITTER}M${MISMATCH}/${OUT}.fastq | awk '/^@/ {c++} END {print c/2}'
```

In addition to generating an interleaved FASTQ file, `scarecrow` outputs a JSON file indicating the barcode and UMI positions on read 1, and the parameters required to use the file with the `kb count` tool of `kallisto-bustools`. In addition, the tools outputs a `_mismatch_stats.csv` and a `_position_stats.csv` file. The mismatch_stats CSV has the following format:

```bash
mismatches,count
-3,3434872
-2,2328623
-1,13064342
0,126768927
1,12071412
2,6884512
3,1214758
4,991680
5,422505
6,293141
```

Indicating the number of reads recorded for each sum of mismatches across its barcodes. For example, allowing up to 2 mismatches for 3 barcodes will sum to 6 if each barcode has 2 mismatches. Negative numbers indicate the number of reads for which no barcode was found (i.e. -1 is one barcode unmatched, -2 is two barcodes unmatched, ...).

The position_stats CSV follows a similar format, indicating the count of barcodes starting at each position within `--jitter 2` :

```bash
position,count
10,3599189
11,154669696
12,1449340
13,525384
47,2067460
48,9485814
49,146188365
50,2350402
51,667344
77,3619040
78,13545713
79,133008992
80,2252858
81,144060
9,824455
N,28026204
```

This illustrates that millions of reads have barcodes not starting at the expected positions.


### 4. Sift reads with invalid barcodes

Reads with one or more invalid barcode are uninformative in downstream analyses as they could not be confidently demultiplexed. We can filter these reads out either by using the `--sift` flag when running `reap`, or by using the `sift` tool afterwards. Here we demonstrate `sift` after running `reap`. As we are providing a `scarecrow` FASTQ input we also need to provide the accompanying JSON file. If a `scarecrow` SAM input is provided then no JSON file is required.

```bash
FASTQ=${PROJECT}/extracted/J${JITTER}M${MISMATCH}/*.fastq
sbatch -p uoa-compute --ntasks 1 --mem 2G --time=12:00:00 -o sift.%j.out -e sift.%j.err \
            scarecrow sift --in ${FASTQ} --json ${FASTQ%.fastq}.json
```


### 5. Trim TSO sequences

To improve downstream alignment results it is highly recommended to trim the reads to remove and adapter sequences or template switching oligo (TSO) sequences. Not all reads possess these sequences, and those that do will not necessarily share the same start position. There is an updated fastqc contaminants list in the Parse splitpipe repo, which we can format for use with cutadapt and supplement with the Parse TSO sequence `AACGCAGAGTGAATGGG`. Below illustrates how this was achieved, and for convenience we have included in the `scarecrow` repo the processed [contaminants list](../contaminants/contaminants.fasta). Note, we use the `-G` rather than the `-g` flag for `cutadapt` because the sequence to be trimmed is on the read 2 output by `scarecrow`, rather than read 1 - which now sotres the barcode and UMI sequences.

```bash
CONTAMINANTS=./software/ParseBiosciences-Pipeline.1.4.1/splitpipe/scripts/config/fastqc-contaminant_list.txt
awk '
# Skip blank lines and comment lines
NF && $0 !~ /^#/ {
  seq = $NF
  header = ""
  for (i = 1; i < NF; i++) {
    header = header $i " "
  }
  gsub(/[ \t]+$/, "", header)
  # Use a separate array to track seen sequences
  if (header != "" && !(seq in seen)) {
    seen[seq] = 1
    print ">" header
    print seq
  }
}
' ${CONTAMINANTS} > ${PROJECT}/contaminants.fasta

# Add Parse Bio TSO sequence to contaminants
sed -i '$ a >Parse Bio TSO sequence\nAACGCAGAGTGAATGGG' ./${PROJECT}/contaminants.fasta

FASTQ=$(basename ${PROJECT}/extracted/J${JITTER}M${MISMATCH}/*_sift.fastq)
sbatch -p uoa-compute --ntasks 1 --cpus-per-task 4 --mem 16G --time=12:00:00 -o cutadapt.%j.out -e cutadapt.%j.err \
    cutadapt --cores 4 --trim-n --minimum-length 30 --interleaved \
        -G file:${PROJECT}/contaminants.fasta \
        -o ${PROJECT}/extracted/J${JITTER}M${MISMATCH}/${FASTQ%_sift.fastq}_trimmed.fastq \
        ${PROJECT}/extracted/J${JITTER}M${MISMATCH}/${FASTQ}
```


### 6. Generate barcode statistics

```bash
FASTQ=${PROJECT}/extracted/J${JITTER}M${MISMATCH}/*_trimmed.fastq
sbatch -p uoa-compute --ntasks 1 --mem 4G --time=12:00:00 -o stats.%j.out -e stats.%j.err \
            scarecrow stats --in ${FASTQ}
```


### 7. Generate count matrix via kallisto-bustools

Next we can generate a count matrix using `kallisto`. There is a script in the scarecrow repo, [kallisto.sh](../src/HPC/kallisto.sh), that parses the JSON file generated by `reap` to retrieve the `-x` string required for running the FASTQ file with `kb count`. This requires the JSON sed-like processor, [`jq`](https://jqlang.org), to be installed. This enables the `-x` flag to be extracted as follows:

```bash
XSTR=$(${jq} -r '."kallisto-bustools"[0]."kb count" | capture("-x (?<x>[^ ]+)").x' ${JSON})
```

The `kallisto.sh` script requires the `kallisto` `--index` and `--genes` for the reference assembly in question, in addition to the FASTQ and JSON files generated by `scarecrow`.

```bash
mkdir -p ${PROJECT}/kallisto/J${JITTER}M${MISMATCH}
FASTQ=$(basename ${PROJECT}/extracted/J${JITTER}M${MISMATCH}/*_trimmed.fastq)
sbatch -p uoa-compute --ntasks 1 --cpus-per-task 8 --mem 4G --time=12:00:00 \
    ~/sharedscratch/scarecrow/scripts/kallisto.sh \
        --index /uoa/scratch/users/s14dw4/software/kallisto/hg38/transcriptome.idx \
        --genes /uoa/scratch/users/s14dw4/software/kallisto/hg38/transcripts_to_genes.txt \
        --fastq ${PROJECT}/extracted/J${JITTER}M${MISMATCH}/${FASTQ} \
        --json ${PROJECT}/extracted/J${JITTER}M${MISMATCH}/${FASTQ%_trimmed.fastq}.json \
        --out ${PROJECT}/kallisto/J${JITTER}M${MISMATCH}/${FASTQ%.fastq}
```


### 8. Generate count matrix via STAR and umi-tools

Before aligning with STAR, if we wish to incoprorate the barcode and UMI read tags we should first recast the FASTQ file to SAM format.

```bash
FASTQ=${PROJECT}/extracted/J${JITTER}M${MISMATCH}/*_trimmed.fastq
sbatch -p uoa-compute --ntasks 1 --mem 2G --time=24:00:00 -o recast.%j.out -e recast.%j.err \
            scarecrow recast --in ${FASTQ}
```


Next, we align with `STAR` from `scarecow` SAM format. For fair comparison with the Parse split-pipe results, we include the `--clip3pAdapterSeq` used in their pipeline.

```bash
mkdir -p ${OUT}
ID=$(basename ${SAM%.sam})
/uoa/scratch/users/s14dw4/software/STAR --runThreadN ${SLURM_CPUS_PER_TASK} \
        --genomeDir ${GENOME} \
        --readFilesIn ${SAM} \
        --readFilesType SAM SE \
        --outFileNamePrefix ${OUT}/${ID}. \
        --outSAMtype BAM Unsorted \
        --clip3pAdapterSeq CCACAGTCTCAAGCACGTGGAT \
        --outFilterMultimapNmax 3
```

The script is run on the HPC as follows:

```bash
GENOME=/uoa/scratch/users/s14dw4/spipe/genomes/hg38
SAM=${PROJECT}/extracted/J${JITTER}M${MISMATCH}/*_trimmed.sam
sbatch -p uoa-compute --ntasks 1 --cpus-per-task 32 --mem 24G --time=02:00:00 -o star.%j.out -e star.%j.err \
    ./scarecrow/scripts/star_align_sam_parse.sh \
        --genome ${GENOME} \
        --sam ${SAM} \
        --out ${PROJECT}/star/J${JITTER}M${MISMATCH}
```


Next step is to run `umi-tools`. The reference GTF file we use for this has a slighltly different config naming convention to the reference we used for alignment with `STAR`. To address this issue we generate an alias file for use with `featureCounts` from the `subread` package, see the `umi-tools` [single-cell tutorial](https://umi-tools.readthedocs.io/en/latest/Single_cell_tutorial.html) for more details. We have included a script in the `scarecrow` repo, [umi_tools.sh](../src/HPC/umi_tools.sh) which runs `featureCounts` followed by `umi-tools count` to generate a counts matrix.

```bash
GTF=/uoa/scratch/shared/Morgan_Lab/common_resources/cellranger/reference/refdata-gex-GRCh38-2020-A/genes/genes.gtf
BAM=${PROJECT}/star/J${JITTER}M${MISMATCH}/*.bam

# Need to create contig look-up as GTF does not have hg38_ prefix to contigs
mkdir -p ${PROJECT}/umi_tools/J${JITTER}M${MISMATCH}
samtools view -H ${BAM} | cut -f2 | grep "^SN" | sed 's/SN://g' | \
    awk '{split($0, TIG, "_"); print TIG[2]","$0;}' > ${PROJECT}/umi_tools/alias.file

# Run UMI-tools
sbatch --partition uoa-compute ./scarecrow/scripts/umi_tools.sh \
    --bam ${BAM} \
    --gtf ${GTF} \
    --out ${PROJECT}/umi_tools/J${JITTER}M${MISMATCH} \
    --alias ${PROJECT}/umi_tools/alias.file
```


Next, the umi_tools output can be converted to a matrix format for downstream processing in R in a similar manner to the `kallisto` output.

```bash
COUNTS=${PROJECT}/umi_tools/J${JITTER}M${MISMATCH}/*.featureCounts.counts.tsv.gz
sbatch --partition uoa-compute ./scarecrow/scripts/counts2mtx.sh --in ${COUNTS}
```
