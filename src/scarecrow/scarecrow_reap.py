#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
@author: David Wragg
"""

import os
import gzip
import pandas as pd
import pysam
import multiprocessing as mp
from argparse import RawTextHelpFormatter
from scarecrow.fastq_logging import log_errors, setup_logger, logger
from typing import List, Tuple, Optional, Dict, Any
import itertools
from functools import partial

def parser_reap(parser):
    subparser = parser.add_parser(
        "reap",
        description="""
Extract sequence range from one fastq file of a pair, and annotate the sequence header with barcode 
sequences based on predicted positions generated by scarecrow harvest.

Example:

scarecrow reap R1.fastq.gz R2.fastq.gz\n\t--barcode_positions barcode_positions.csv\n\t--barcodes BC1:bc1_whitelist.txt BC2:bc2_whitelist.txt BC3:bc3_whitelist.txt\n\t--read2 0-100 --out cdna.fastq
---
""",
        epilog="The --barcodes <name> must match the barcode_whitelist values in the --barcode_positions file.",
        help="Extract sequence range from fastq files",
        formatter_class=RawTextHelpFormatter,
    )
    subparser.add_argument("fastqs", nargs="+", help="List of FASTQ files")
    subparser.add_argument(
        "-o", "--out",
        metavar="out.fastq",
        help=("Path to output fastq file"),
        type=str,
        default='extracted.fastq',
    )
    subparser.add_argument(
        "-p", "--barcode_positions",
        metavar="barcode_positions",
        help=("File containing barcode positions, output by scarecrow harvest"),
        type=str,
        default=[],
    )
    subparser.add_argument(
        "-j", "--jitter",
        metavar="jitter",
        type=int,
        default=5,
        help='Barcode position jitter [5]',
    )
    group = subparser.add_mutually_exclusive_group(required=True)
    group.add_argument(
        "-1", "--read1",
        metavar="read1_range",
        help=("Sequence range to extract from read1 (e.g. (0-100))"),
        type=str,
        default=None
    )
    group.add_argument(
        "-2", "--read2",
        metavar="read2_range",
        help=("Sequence range to extract from read2 (e.g. 0-100)"),
        type=str,
        default=None
    )
    subparser.add_argument(
        "-c", "--barcodes",
        metavar="barcodes",
        nargs='+', 
        help='Barcode whitelist files in format <name>:<file> (e.g. BC1:barcodes1.txt BC2:barcodes2.txt)',
    )
    subparser.add_argument(
        "-b", "--batch_size",
        metavar="batch_size",
        help=("Number of read pairs per batch to process at a time [10000]"),
        type=int,
        default=10000,
    )
    subparser.add_argument(
        "-@", "--threads",
        metavar="threads",
        help=("Number of processing threads [4]"),
        type=int,
        default=4,
    )
    subparser.add_argument(
        "-l", "--logfile",
        metavar="logfile",
        help=("File to write log to"),
        type=str,
        default="./scarecrow.log",
    )
    return subparser

def validate_reap_args(parser, args):
    run_reap(fastqs = [f for f in args.fastqs], 
             barcode_positions = args.barcode_positions,
             output = args.out,
             read1_range = args.read1,
             read2_range = args.read2, 
             barcodes = args.barcodes,
             jitter = args.jitter,
             batches = args.batch_size, 
             threads = args.threads,
             logfile = args.logfile)


@log_errors
def run_reap(fastqs: List[str], 
             barcode_positions: str,
             output: str = 'extracted.fastq',
             read1_range: Optional[str] = None,
             read2_range: Optional[str] = None,
             barcodes: List[str] = None,
             jitter: int = 5,
             batches: int = 10000,
             threads: int = 4,
             logfile: str = './scarecrow.log') -> None:
    """
    Main function to extract sequences with barcode headers
    """    
    # Global logger setup
    logger = setup_logger(logfile)

    extractor = MemoryEfficientParallelFASTQExtractor(
        fastq_files = [f for f in fastqs],
        barcode_positions_file = barcode_positions,
        output = output,
        read1_range = read1_range,
        read2_range = read2_range,
        jitter = jitter,
        batch_size = batches,
        threads = threads
    )
    extractor.extract_sequences()

   
def process_read_batch(
    read_batch: List[Tuple[Any, Any]], 
    barcode_configs: List[Dict[str, Any]], 
    read1_range: Optional[Tuple[int, int]], 
    read2_range: Optional[Tuple[int, int]]
) -> List[str]:
    """
    Process a batch of reads, extracting barcodes and sequences
    
    Args:
        read_batch: List of tuples containing (read1, read2) entries
        barcode_configs: Configurations for barcode extraction
        read1_range: Range to extract from read1 if applicable
        read2_range: Range to extract from read2 if applicable
    
    Returns:
        List of formatted FASTQ entries
    """
    output_entries = []
    for r1_entry, r2_entry in read_batch:
        # Extract barcodes
        barcodes = []
        for config in barcode_configs:
            seq = r1_entry.sequence if config['file_index'] == 0 else r2_entry.sequence
            barcode = seq[config['jittered_start']:config['jittered_end']]
            barcodes.append(barcode)
        
        # Determine which read to extract from
        if read1_range:
            extract_seq = r1_entry.sequence[read1_range[0]:read1_range[1]]
            extract_qual = r1_entry.quality[read1_range[0]:read1_range[1]]
            source_entry = r1_entry
        else:
            extract_seq = r2_entry.sequence[read2_range[0]:read2_range[1]]
            extract_qual = r2_entry.quality[read2_range[0]:read2_range[1]]
            source_entry = r2_entry
        
        # Modify header with barcodes
        new_header = f"{source_entry.name}_{('_').join(barcodes)}"
        
        # Create FASTQ entry
        output_entries.append(f"@{new_header}\n{extract_seq}\n+\n{extract_qual}\n")
    
    return output_entries



@log_errors
class MemoryEfficientParallelFASTQExtractor:
    def __init__(self, 
                 fastq_files: List[str], 
                 barcode_positions_file: str, 
                 output: str = 'extracted.fastq', 
                 read1_range: Optional[str] = None,
                 read2_range: Optional[str] = None,
                 jitter: int = 5, 
                 batch_size: int = 100000,
                 threads: int = None):
        """
        Initialize FASTQ extractor with parallel processing and memory-efficient design
        """
        self.fastq_files = fastq_files
        self.barcode_positions = pd.read_csv(barcode_positions_file)
        print("\033[34m\nBarcode positional data:\033[0m")
        print(f"{self.barcode_positions}")

        self.output = output
        self.jitter = jitter
        
        # Parse read ranges
        self.read1_range = self._parse_range(read1_range) if read1_range else None
        self.read2_range = self._parse_range(read2_range) if read2_range else None
        
        # Prepare barcode extraction configurations
        self.barcode_configs = self._prepare_barcode_configs()
        
        # Parallel processing settings
        self.batch_size = batch_size
        self.threads = threads or (mp.cpu_count() - 1 or 1)
        
        # Ensure output directory exists
        os.makedirs(os.path.dirname(self.output) or '.', exist_ok=True)

    def _parse_range(self, range_str: str) -> Tuple[int, int]:
        """Parse string range like '0-100' into start and end integers"""
        start, end = map(int, range_str.split('-'))
        return (start, end)

    def _prepare_barcode_configs(self) -> List[Dict[str, Any]]:
        """Prepare barcode extraction configurations"""
        configs = []
        for idx, row in self.barcode_positions.iterrows():
            config = {
                'index': idx,
                'file_index': 0 if row['read'] == 'read1' else 1,
                'start': row['start'],
                'end': row['end'],
                'jittered_start': max(0, row['start'] - self.jitter),
                'jittered_end': row['end'] + self.jitter
            }
            configs.append(config)
        return configs

    def extract_sequences(self):
        """Extract sequences to FASTQ with modified headers using parallel processing"""
        read1, read2 = self.fastq_files
        
        # Determine output file opening method
        out_mode = 'wt' if not self.output.endswith('.gz') else 'wt'
        open_func = gzip.open if self.output.endswith('.gz') else open
        
        with pysam.FastqFile(read1) as r1, \
             pysam.FastqFile(read2) as r2, \
             open_func(self.output, out_mode) as out_fastq:
            
            # Create read pair iterator
            read_pairs = zip(r1, r2)
            
            # Prepare partial function for multiprocessing
            process_batch_func = partial(
                process_read_batch, 
                barcode_configs=self.barcode_configs,
                read1_range=self.read1_range,
                read2_range=self.read2_range
            )
            
            # Process in batches with multiprocessing
            with mp.Pool(processes=self.threads) as pool:
                # Create batches of reads
                batch_iterator = iter(lambda: list(itertools.islice(read_pairs, self.batch_size)), [])
                
                for batch in batch_iterator:
                    if not batch:
                        break
                    
                    # Process batch in parallel
                    processed_entries = pool.map(process_batch_func, [batch])
                    
                    # Flatten and write results
                    for entry in itertools.chain.from_iterable(processed_entries):
                        out_fastq.write(entry)