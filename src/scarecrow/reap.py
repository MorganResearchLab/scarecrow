# -*- coding: utf-8 -*-
"""
#!/usr/bin/env python3
@author: David Wragg
"""

import os
import gzip
import pandas as pd
import pysam
import random
import multiprocessing as mp
from argparse import RawTextHelpFormatter
import logging
from scarecrow.logger import log_errors, setup_logger
from scarecrow.seed import parse_seed_arguments
from scarecrow.tools import generate_random_string, reverse_complement
from typing import List, Tuple, Optional, Dict, Any, Union
import itertools
from functools import partial
import ast
from collections import defaultdict
from Bio.Seq import Seq  # For faster reverse complement
import numpy as np  # For faster Hamming distance calculation


def parser_reap(parser):
    subparser = parser.add_parser(
        "reap",
        description="""
Extract sequence range from one fastq file of a pair, and annotate the sequence header with barcode 
sequences based on predicted positions generated by scarecrow harvest.

Example:

scarecrow reap --fastqs R1.fastq.gz R2.fastq.gz\n\t--barcode_positions barcode_positions.csv\n\t--barcodes BC1:v1_whitelist:bc1_whitelist.txt BC2:v2_whitelist:bc2_whitelist.txt BC3:v1_whitelist:bc3_whitelist.txt\n\t--read2 0-100 --out cdna.fastq
---
""",
        epilog="The --barcodes <name> must match the barcode_whitelist values in the --barcode_positions file.",
        help="Extract sequence range from fastq files",
        formatter_class=RawTextHelpFormatter,
    )
    subparser.add_argument(
        "--fastqs", 
        nargs="+", 
        help="Pair of FASTQ files")
    subparser.add_argument(
        "-o", "--out",
        metavar="out.fastq",
        help=("Path to output fastq file"),
        type=str,
        default='extracted.fastq',
    )
    subparser.add_argument(
        "-p", "--barcode_positions",
        metavar="barcode_positions",
        help=("File containing barcode positions, output by scarecrow harvest"),
        type=str,
        default=[],
    )
    subparser.add_argument(
        "-j", "--jitter",
        metavar="jitter",
        type=int,
        default=5,
        help='Barcode position jitter [5]',
    )
    subparser.add_argument(
        "-m", "--mismatches",
        metavar="mismatches",
        type=int,
        default=1,
        help='Number of allowed mismatches in barcode [1]',
    )
    group = subparser.add_mutually_exclusive_group(required=True)
    group.add_argument(
        "-1", "--read1",
        metavar="read1_range",
        help=("Sequence range to extract from read1 (e.g. (0-100))"),
        type=str,
        default=None
    )
    group.add_argument(
        "-2", "--read2",
        metavar="read2_range",
        help=("Sequence range to extract from read2 (e.g. 0-100)"),
        type=str,
        default=None
    )
    subparser.add_argument(
        "-c", "--barcodes",
        metavar="barcodes",
        nargs='+', 
        help='Barcode whitelist files in format <name>:<file> (e.g. BC1:barcodes1.txt BC2:barcodes2.txt)',
    )
    subparser.add_argument(
        "-b", "--batch_size",
        metavar="batch_size",
        help=("Number of read pairs per batch to process at a time [10000]"),
        type=int,
        default=10000,
    )
    subparser.add_argument(
        "-@", "--threads",
        metavar="threads",
        help=("Number of processing threads [4]"),
        type=int,
        default=4,
    )
    subparser.add_argument(
        "-v", "--verbose",
        action='store_true',
        help='Enable verbose output [false]'
    )
    return subparser

def validate_reap_args(parser, args):
    run_reap(fastqs = [f for f in args.fastqs], 
             barcode_positions = args.barcode_positions,
             output = args.out,
             read1_range = args.read1,
             read2_range = args.read2, 
             barcodes = args.barcodes,
             jitter = args.jitter,
             mismatches = args.mismatches,
             batches = args.batch_size, 
             threads = args.threads,
             verbose = args.verbose)

@log_errors
def run_reap(fastqs: List[str], 
             barcode_positions: str,
             output: str = 'extracted.fastq',
             read1_range: Optional[str] = None,
             read2_range: Optional[str] = None,
             barcodes: List[str] = None,
             jitter: int = 5,
             mismatches: int = 1,
             batches: int = 10000,
             threads: int = 4,
             verbose: bool = False) -> None:
    """
    Main function to extract sequences with barcode headers
    """    
    # Global logger setup
    logfile = '{}_{}.{}'.format('./scarecrow_reap', generate_random_string(), 'log')
    logger = setup_logger(logfile)
    logger.info(f"logfile: ${logfile}")

    # Extract barcodes and convert whitelist to set
    expected_barcodes = parse_seed_arguments(barcodes)  
    logger.info(f"Barcode whitelist:")
    for key, barcode in expected_barcodes.items():
        expected_barcodes[key] = sorted(set(barcode))
        if verbose:
            logger.info(f"{key}: {barcode}")

    # Extract barcodes and target sequence
    extract_sequences_parallel_optimized(
        fastq_files = [f for f in fastqs],
        barcode_positions_file = barcode_positions,
        barcode_sequences = expected_barcodes,
        output = output,
        read1_range = read1_range,
        read2_range = read2_range,
        jitter = jitter,
        mismatches = mismatches,
        batch_size = batches,
        threads = threads,
        verbose = verbose
    )
    
    # Process fastq header
    barcode_counts, cell_barcodes = process_fastq_headers(output)
    # Log the barcode counts for each position
    for i, counts in enumerate(barcode_counts):
        if verbose:
            for barcode, count in counts.items():
                logger.info(f"Barcode index: {i + 1}\tBarcode: {barcode}\tCount: {count}")
        barcodes = pd.DataFrame(list(barcode_counts[i].items()), columns=["Barcode", "Count"]).sort_values(by="Count")
        barcodes.insert(0, "Index", i + 1)
        if i == 0:
            barcodes.to_csv('{}.{}'.format(output, 'barcode.counts.csv'), index = False)
        else:
            barcodes.to_csv('{}.{}'.format(output, 'barcode.counts.csv'), index = False, mode = "a", header = False)

    # Log the combined barcode counts (i.e. cell sequence counts)
    if verbose:
        for cell, count in cell_barcodes.items():
            logger.info(f"Cell barcode: {cell}\tCount: {count}")
    barcodes = pd.DataFrame(list(cell_barcodes.items()), columns=["CellBarcode", "Count"]).sort_values(by="Count")
    barcodes.to_csv('{}.{}'.format(output, 'cell.counts.csv'), index = False)


def parse_range(range_str: str) -> Tuple[int, int]:
    """Parse string range like '0-100' into start and end integers"""
    start, end = map(int, range_str.split('-'))
    return (start, end)

def prepare_barcode_configs(barcode_positions: pd.DataFrame, jitter: int) -> List[Dict[str, Any]]:
    """Prepare barcode extraction configurations"""
    configs = []
    for idx, row in barcode_positions.iterrows():
        config = {
            'index': idx,
            'file_index': 0 if row['read'] == 'read1' else 1,
            'start': row['start'],
            'end': row['end'],
            'orientation': row['orientation'],
            'jittered_start': max(0, row['start'] - jitter),
            'jittered_end': row['end'] + jitter + 1,
            'whitelist': row['barcode_whitelist']
        }
        configs.append(config)
    return configs




def process_fastq_headers(file_path):
    """
    Process fastq header to report on barcode counts

    Args:
        file_path: fastq file to operate on
    
    Returns:
        List of barcode counts and list of barcode combination counts
    """

    # Create a list of dictionaries, one for each barcode position
    barcode_counts = []
    cell_barcodes = defaultdict(int)

    # Open the FASTQ file using pysam
    with pysam.FastxFile(file_path) as fastq_file:
        for entry in fastq_file:
            # Extract the header line
            header = entry.comment

            # Check if the header contains 'barcodes='
            if 'barcodes=' in header:
                # Extract the barcodes string (everything after 'barcodes=')
                barcodes_str = header.split('barcodes=')[1]
                cell_barcodes[barcodes_str] += 1
                
                # Split the barcodes string by underscore
                barcodes = barcodes_str.split('_')
                
                # Ensure barcode_counts has enough dictionaries for all barcode positions
                while len(barcode_counts) < len(barcodes):
                    barcode_counts.append(defaultdict(int))
                
                # Update counts in the corresponding dictionaries
                for i, barcode in enumerate(barcodes):
                    barcode_counts[i][barcode] += 1

    return barcode_counts, cell_barcodes



def match_barcode_optimized(sequence: str, barcodes: set, orientation: str, max_mismatches: int, 
                            jitter: int) -> List[Dict]:
    """
    Optimized barcode matching function using vectorized operations and early exits.
    """
    logger = logging.getLogger('scarecrow')

    logger.debug(f"""
        Matching parameters:
        Sequence length: {len(sequence)}
        Number of barcodes: {len(barcodes)}
        Orientation: {orientation}
        Max mismatches: {max_mismatches}
        Jitter: {jitter}
        """)

    barcode_len = len(next(iter(barcodes)))  # Get length of first barcode
    candidate = sequence if orientation != 'reverse' else str(Seq(sequence).reverse_complement())

    print(f"First few barcodes: {list(barcodes)[:3]}")
    print(f"Candidate sequence: {candidate}")
    print(f"Candidate type: {type(candidate)}")
    print(f"First barcode type: {type(next(iter(barcodes)))}")
    
    # Check for hidden characters or whitespace
    print(f"Candidate bytes: {candidate.encode()}")
    print(f"First barcode bytes: {next(iter(barcodes)).encode()}")


    # Quick exact match check using set operations
    matches = []
    for i in range(len(candidate) - barcode_len + 1):
        substring = candidate[i:i + barcode_len]
        print(f"Checking substring: '{substring}' at position {i}")
        print(f"Is in barcodes: {substring in barcodes}")
        if substring in barcodes:
            match = [{
                'barcode': substring,
                'sequence': candidate,
                'start': i + 1,
                'end': i + barcode_len,
                'mismatches': 0,
                'peak_dist': 0
            }]
            print(f"Match found: {match}")
            return match       
        # Test explicit set membership (debugging chunk)
        test_set = set()
        for barcode in barcodes:
            test_set.add(barcode.strip())  # Remove any hidden whitespace
            if substring.strip() == barcode.strip():
                print(f"Found match through explicit comparison: {barcode}")

    # If no exact match, use numpy for efficient Hamming distance calculation
    if max_mismatches > 0:
        barcode_array = np.array([list(b) for b in barcodes])       
        seq_len = len(candidate)
        max_steps = max(jitter, seq_len - jitter - barcode_len + 1)

        # Search bidirectionally
        for step in range(max_steps):
            left_matches = []
            right_matches = []
            
            # Position before jitter point
            left_pos = jitter - step
            if left_pos >= 0:
                # Fix broadcasting issue by reshaping substr_array
                substr = candidate[left_pos:left_pos + barcode_len]
                if len(substr) == barcode_len:  # Ensure we have a full barcode length
                    substr_array = np.array(list(substr))[np.newaxis, :]
                    distances = np.sum(barcode_array != substr_array, axis=1)

                    print(f"Candidate length: {len(candidate)}")
                    print(f"Left pos: {left_pos}, Barcode len: {barcode_len}")
                    print(f"Substr: {substr}, Length: {len(substr)}")
                    
                    # Check for matches at left position
                    for b, d in zip(barcodes, distances):
                        if d <= max_mismatches:
                            match = {
                                'barcode': b,
                                'sequence': candidate,
                                'start': left_pos + 1,  # 1-based indexing
                                'end': left_pos + barcode_len,
                                'mismatches': int(d),
                                'peak_dist': abs(jitter - left_pos) if jitter is not None else None,
                                'position': 'left'
                            }
                            # Return immediately if perfect match
                            if d == 0:
                                print(f"Match found: {matches}")
                                return [match]
                            left_matches.append(match)
                
            # Position after jitter point
            right_pos = jitter + step
            if right_pos <= seq_len - barcode_len and right_pos != left_pos:
                # Fix broadcasting issue by reshaping substr_array
                substr = candidate[right_pos:right_pos + barcode_len]
                if len(substr) == barcode_len:  # Ensure we have a full barcode length
                    substr_array = np.array(list(substr))[np.newaxis, :]
                    distances = np.sum(barcode_array != substr_array, axis=1)
                    
                    # Check for matches at right position
                    for b, d in zip(barcodes, distances):
                        if d <= max_mismatches:
                            match = {
                                'barcode': b,
                                'sequence': candidate,
                                'start': right_pos + 1,  # 1-based indexing
                                'end': right_pos + barcode_len,
                                'mismatches': int(d),
                                'peak_dist': abs(jitter - right_pos) if jitter is not None else None,
                                'position': 'right'
                            }
                            # Return immediately if perfect match
                            if d == 0:
                                print(f"Match found: {matches}")
                                return [match]
                            right_matches.append(match)
            
            # If we have matches, handle according to priority rules
            if left_matches or right_matches:
                # Get best matches from each side (lowest number of mismatches)
                left_best = min(left_matches, key=lambda x: x['mismatches']) if left_matches else None
                right_best = min(right_matches, key=lambda x: x['mismatches']) if right_matches else None
                
                # If we have matches on both sides with same number of mismatches
                if (left_best and right_best and 
                    left_best['mismatches'] == right_best['mismatches']):
                    chosen_match = random.choice([left_best, right_best])
                    print(f"Match found: {matches}")
                    return [chosen_match]
                
                # Return the best match (the one with fewer mismatches)
                elif left_best and (not right_best or 
                                left_best['mismatches'] < right_best['mismatches']):
                    print(f"Match found: {matches}")
                    return [left_best]
                elif right_best:
                    print(f"Match found: {matches}")
                    return [right_best]  

    #matches.sort(key=lambda x: (x['mismatches'], x['peak_dist'], x['start']))
    return matches


def process_read_batch_optimized(read_batch: List[Tuple], 
                               barcode_configs: List[Dict], 
                               barcode_sequences: Dict,
                               read1_range: Optional[Tuple], 
                               read2_range: Optional[Tuple],
                               mismatches: int = 1,
                               logfile: str = None,
                               verbose: bool = False) -> List[str]:
    """
    Optimized batch processing with minimal logging and efficient string operations.
    """
    logger = setup_logger(logfile) if logfile else logging.getLogger('scarecrow')
    output_entries = []
    
    # Pre-compute ranges and configurations
    extract_range = read1_range if read1_range else read2_range
    read_index = 0 if read1_range else 1
    
    # Pre-process barcode configurations
    print(f"Barcode configs: {barcode_configs}")

    config_map = {(config['file_index'], config['whitelist']): 
                 (config['jittered_start'], config['jittered_end'], 
                  config['orientation'], abs(config['jittered_start'] - config['start']))
                 for config in barcode_configs}

    for reads in read_batch:
        barcodes = []
        for config in barcode_configs:
            print(f"Config file index: {config['file_index']}")
            print(f"Seq file index 0: {reads[0].sequence}")
            print(f"Seq file index 1: {reads[1].sequence}")
            print(f"Read: {reads[config['file_index']].name}\t{reads[config['file_index']].sequence}")
            seq = reads[config['file_index']].sequence
            start, end, orientation, jitter_dist = config_map[(config['file_index'], config['whitelist'])]
            barcode = seq[start:end]
            
            whitelist = ast.literal_eval(config['whitelist'])[0]
            if whitelist in barcode_sequences:
                print(f"Whitelist: {whitelist}")
                print(f"Available sequences: {list(barcode_sequences.values())}")
                print(f"Number of barcodes: {len(barcode_sequences[whitelist])}")
                matches = match_barcode_optimized(
                    sequence = barcode,
                    barcodes = barcode_sequences[whitelist],
                    orientation = orientation,
                    max_mismatches = mismatches,
                    jitter = jitter_dist
                )
                barcodes.append(matches[0]['barcode'] if matches else 'null')
            else:
                barcodes.append('null')

        # Extract sequence and create output
        source_entry = reads[read_index]
        extract_seq = source_entry.sequence[extract_range[0]:extract_range[1]]
        extract_qual = source_entry.quality[extract_range[0]:extract_range[1]]
        
        # Use join for efficient string concatenation
        header_parts = [source_entry.name, source_entry.comment, f"barcodes={('_').join(barcodes)}"]
        output_entries.append(f"@{' '.join(header_parts)}\n{extract_seq}\n+\n{extract_qual}\n")

    return output_entries

def extract_sequences_parallel_optimized(
    fastq_files: List[str],
    barcode_positions_file: str,
    barcode_sequences: Dict[str, List[str]],
    output: str = 'extracted.fastq',
    read1_range: Optional[str] = None,
    read2_range: Optional[str] = None,
    jitter: int = 5,
    mismatches: int = 1,
    batch_size: int = 100000,
    threads: Optional[int] = None,
    verbose: bool = False
) -> None:
    """
    Optimized parallel sequence extraction with improved I/O handling and memory management.
    """
    logger = setup_logger(f'./scarecrow_reap_{generate_random_string()}.log')
    
    # Load and parse configurations once
    barcode_positions = pd.read_csv(barcode_positions_file)
    barcode_configs = prepare_barcode_configs(barcode_positions, jitter)
    
    # Parse ranges once
    parsed_read1_range = parse_range(read1_range) if read1_range else None
    parsed_read2_range = parse_range(read2_range) if read2_range else None
    
    # Optimize thread count
    threads = min(threads or mp.cpu_count(), batch_size // 1000 or 1)
    
    # Set up output handling
    out_mode = 'wt' if not output.endswith('.gz') else 'wt'
    open_func = gzip.open if output.endswith('.gz') else open
    os.makedirs(os.path.dirname(output) or '.', exist_ok=True)

    # Process files with optimized batching
    with pysam.FastqFile(fastq_files[0]) as r1, \
         pysam.FastqFile(fastq_files[1]) as r2, \
         open_func(output, out_mode) as out_fastq:
        
        # Create efficient process_batch function
        process_batch_func = partial(
            process_read_batch_optimized,
            barcode_configs = barcode_configs,
            barcode_sequences = barcode_sequences,
            mismatches = mismatches,
            read1_range = parsed_read1_range,
            read2_range = parsed_read2_range,
            verbose = verbose
        )

        # Efficient parallel processing with proper chunking
        with mp.Pool(processes=threads) as pool:
            read_pairs = zip(r1, r2)
            while True:
                batch = list(itertools.islice(read_pairs, batch_size))
                if not batch:
                    break
                    
                # Process batch and write results immediately
                for processed_entries in pool.imap_unordered(process_batch_func, [batch]):
                    out_fastq.writelines(processed_entries)
