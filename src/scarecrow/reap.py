# -*- coding: utf-8 -*-
"""
#!/usr/bin/env python3
@author: David Wragg
"""

import os
import gzip
import pandas as pd
import pysam
import random
import multiprocessing as mp
from argparse import RawTextHelpFormatter
import logging
from scarecrow.logger import log_errors, setup_logger
from scarecrow.seed import parse_seed_arguments
from scarecrow.tools import generate_random_string
from typing import List, Tuple, Optional, Dict, Any, Set
import itertools
from functools import partial, lru_cache
import ast
from collections import defaultdict
import numpy as np
from Bio.Seq import Seq



def parser_reap(parser):
    subparser = parser.add_parser(
        "reap",
        description="""
Extract sequence range from one fastq file of a pair, and annotate the sequence header with barcode 
sequences based on predicted positions generated by scarecrow harvest.

Example:

scarecrow reap --fastqs R1.fastq.gz R2.fastq.gz\n\t--barcode_positions barcode_positions.csv\n\t--barcodes BC1:v1_whitelist:bc1_whitelist.txt BC2:v2_whitelist:bc2_whitelist.txt BC3:v1_whitelist:bc3_whitelist.txt\n\t--read2 0-100 --out cdna.fastq
---
""",
        epilog="The --barcodes <name> must match the barcode_whitelist values in the --barcode_positions file.",
        help="Extract sequence range from fastq files",
        formatter_class=RawTextHelpFormatter,
    )
    subparser.add_argument(
        "--fastqs", 
        nargs="+", 
        help="Pair of FASTQ files")
    subparser.add_argument(
        "-o", "--out",
        metavar="out.fastq",
        help=("Path to output fastq file"),
        type=str,
        default='extracted.fastq',
    )
    subparser.add_argument(
        "-p", "--barcode_positions",
        metavar="barcode_positions",
        help=("File containing barcode positions, output by scarecrow harvest"),
        type=str,
        default=[],
    )
    subparser.add_argument(
        "-j", "--jitter",
        metavar="jitter",
        type=int,
        default=5,
        help='Barcode position jitter [5]',
    )
    subparser.add_argument(
        "-m", "--mismatches",
        metavar="mismatches",
        type=int,
        default=1,
        help='Number of allowed mismatches in barcode [1]',
    )
    group = subparser.add_mutually_exclusive_group(required=True)
    group.add_argument(
        "-1", "--read1",
        metavar="read1_range",
        help=("Sequence range to extract from read1 (e.g. (0-100))"),
        type=str,
        default=None
    )
    group.add_argument(
        "-2", "--read2",
        metavar="read2_range",
        help=("Sequence range to extract from read2 (e.g. 0-100)"),
        type=str,
        default=None
    )
    subparser.add_argument(
        "-c", "--barcodes",
        metavar="barcodes",
        nargs='+', 
        help='Barcode whitelist files in format <name>:<file> (e.g. BC1:barcodes1.txt BC2:barcodes2.txt)',
    )
    subparser.add_argument(
        "-b", "--batch_size",
        metavar="batch_size",
        help=("Number of read pairs per batch to process at a time [10000]"),
        type=int,
        default=10000,
    )
    subparser.add_argument(
        "-@", "--threads",
        metavar="threads",
        help=("Number of processing threads [4]"),
        type=int,
        default=4,
    )
    subparser.add_argument(
        "-v", "--verbose",
        action='store_true',
        help='Enable verbose output [false]'
    )
    return subparser

def validate_reap_args(parser, args):
    run_reap(fastqs = [f for f in args.fastqs], 
             barcode_positions = args.barcode_positions,
             output = args.out,
             read1_range = args.read1,
             read2_range = args.read2, 
             barcodes = args.barcodes,
             jitter = args.jitter,
             mismatches = args.mismatches,
             batches = args.batch_size, 
             threads = args.threads,
             verbose = args.verbose)

@log_errors
def run_reap(fastqs: List[str], 
             barcode_positions: str,
             output: str = 'extracted.fastq',
             read1_range: Optional[str] = None,
             read2_range: Optional[str] = None,
             barcodes: List[str] = None,
             jitter: int = 5,
             mismatches: int = 1,
             batches: int = 10000,
             threads: int = 4,
             verbose: bool = False) -> None:
    """
    Main function to extract sequences with barcode headers
    """    
    # Global logger setup
    logfile = '{}_{}.{}'.format('./scarecrow_reap', generate_random_string(), 'log')
    logger = setup_logger(logfile)
    logger.info(f"logfile: ${logfile}")

    # Extract barcodes and convert whitelist to set
    expected_barcodes = parse_seed_arguments(barcodes)  
    for key, barcode in expected_barcodes.items():
        expected_barcodes[key] = sorted(set(barcode))
        if verbose:
            logger.info(f"{key}: {barcode}")

    # Extract barcodes and target sequence
    ###    barcode_positions_file = barcode_positions,
    #extract_sequences_parallel_optimized(
    #    fastq_files = [f for f in fastqs],
    #    barcode_sequences = expected_barcodes,
    #    output = output,
    #    read1_range = read1_range,
    #    read2_range = read2_range,
    #    jitter = jitter,
    #    mismatches = mismatches,
    #    batch_size = batches,
    #    threads = threads,
    #    verbose = verbose
    #)
    extract_sequences_parallel(
        fastq_files = [f for f in fastqs],
        barcode_positions_file = barcode_positions,
        barcode_sequences = expected_barcodes,
        output = output,
        read1_range = read1_range,
        read2_range = read2_range,
        jitter = jitter,
        mismatches = mismatches,
        batch_size = batches,
        threads = threads
    )
    
    # Process fastq header
    barcode_counts, cell_barcodes = process_fastq_headers(output)
    # Log the barcode counts for each position
    for i, counts in enumerate(barcode_counts):
        if verbose:
            for barcode, count in counts.items():
                logger.info(f"Barcode index: {i + 1}\tBarcode: {barcode}\tCount: {count}")
        barcodes = pd.DataFrame(list(barcode_counts[i].items()), columns=["Barcode", "Count"]).sort_values(by="Count")
        barcodes.insert(0, "Index", i + 1)
        if i == 0:
            barcodes.to_csv('{}.{}'.format(output, 'barcode.counts.csv'), index = False)
        else:
            barcodes.to_csv('{}.{}'.format(output, 'barcode.counts.csv'), index = False, mode = "a", header = False)

    # Log the combined barcode counts (i.e. cell sequence counts)
    if verbose:
        for cell, count in cell_barcodes.items():
            logger.info(f"Cell barcode: {cell}\tCount: {count}")
    barcodes = pd.DataFrame(list(cell_barcodes.items()), columns=["CellBarcode", "Count"]).sort_values(by="Count")
    barcodes.to_csv('{}.{}'.format(output, 'cell.counts.csv'), index = False)

def process_fastq_headers(file_path):
    """
    Process fastq header to report on barcode counts

    Args:
        file_path: fastq file to operate on
    
    Returns:
        List of barcode counts and list of barcode combination counts
    """

    # Create a list of dictionaries, one for each barcode position
    barcode_counts = []
    cell_barcodes = defaultdict(int)

    # Open the FASTQ file using pysam
    with pysam.FastxFile(file_path) as fastq_file:
        for entry in fastq_file:
            # Extract the header line
            header = entry.comment

            # Check if the header contains 'barcodes='
            if 'barcodes=' in header:
                # Extract the barcodes string (everything after 'barcodes=')
                barcodes_str = header.split('barcodes=')[1]
                cell_barcodes[barcodes_str] += 1
                
                # Split the barcodes string by underscore
                barcodes = barcodes_str.split('_')
                
                # Ensure barcode_counts has enough dictionaries for all barcode positions
                while len(barcode_counts) < len(barcodes):
                    barcode_counts.append(defaultdict(int))
                
                # Update counts in the corresponding dictionaries
                for i, barcode in enumerate(barcodes):
                    barcode_counts[i][barcode] += 1

    return barcode_counts, cell_barcodes







class BarcodeMatcherOptimized:
    def __init__(self, barcode_sequences: Dict[str, Set[str]], mismatches: int):
        self.mismatches = mismatches
        self.matchers = {}
        
        # Create optimized lookup structures for each whitelist
        for whitelist, sequences in barcode_sequences.items():
            exact_matches = set(sequences)
            # Create lookup tables for 1-mismatch sequences if needed
            mismatch_lookup = self._create_mismatch_lookup(sequences) if mismatches > 0 else None
            self.matchers[whitelist] = {
                'exact': exact_matches,
                'mismatch': mismatch_lookup,
                'length': len(next(iter(sequences)))
            }

    def _create_mismatch_lookup(self, sequences: Set[str]) -> Dict[str, str]:
        """Create a lookup table for sequences with 1 mismatch"""
        lookup = {}
        for seq in sequences:
            # Store the original sequence
            lookup[seq] = seq
            # Generate all 1-mismatch variants
            for i in range(len(seq)):
                for base in 'ACGTN':
                    if base != seq[i]:
                        variant = seq[:i] + base + seq[i+1:]
                        # Only store if this variant hasn't been seen or is closer to current sequence
                        if variant not in lookup:
                            lookup[variant] = seq
        return lookup

    @lru_cache(maxsize=1024)
    def _reverse_complement(self, sequence: str) -> str:
        """Cached reverse complement computation"""
        return str(Seq(sequence).reverse_complement())

    def find_match(self, sequence: str, whitelist: str, orientation: str) -> str:
        """Find best matching barcode sequence"""
        matcher = self.matchers[whitelist]
        barcode_len = matcher['length']
        
        if len(sequence) < barcode_len:
            return 'null'

        # Handle reverse orientation
        if orientation == 'reverse':
            sequence = self._reverse_complement(sequence)

        # Try exact match first
        if sequence in matcher['exact']:
            return sequence

        # If mismatches allowed, check mismatch lookup
        if self.mismatches > 0 and matcher['mismatch'] is not None:
            if sequence in matcher['mismatch']:
                return matcher['mismatch'][sequence]

        return 'null'

def process_read_batch(read_batch: List[Tuple], 
                      barcode_configs: List[Dict],
                      matcher: BarcodeMatcherOptimized,
                      read_range: Tuple[int, int],
                      read_index: int,
                      verbose: bool) -> List[str]:
    """Process a batch of reads with optimized matching"""
    output_entries = []
    
    for reads in read_batch:
        barcodes = []
        for config in barcode_configs:
            seq = reads[config['file_index']].sequence
            start, end = config['start'], config['end']
            barcode_seq = seq[start-1:end]

            whitelist = ast.literal_eval(config['whitelist'])[0]

            if whitelist in matcher.matchers:
                matched_barcode = matcher.find_match(
                    barcode_seq, whitelist, config['orientation'])

                barcodes.append(matched_barcode)
            else:
                barcodes.append('null')

        # Extract sequence and create output
        source_entry = reads[read_index]
        extract_seq = source_entry.sequence[read_range[0]:read_range[1]]
        extract_qual = source_entry.quality[read_range[0]:read_range[1]]
        
        header = f"@{source_entry.name} {source_entry.comment} barcodes={('_').join(barcodes)}\n"
        output_entries.append(f"{header}{extract_seq}\n+\n{extract_qual}\n")

    return output_entries

def extract_sequences_parallel(
    fastq_files: List[str],
    barcode_positions_file: str,
    barcode_sequences: Dict[str, List[str]],
    output: str = 'extracted.fastq',
    read1_range: Optional[str] = None,
    read2_range: Optional[str] = None,
    jitter: int = 5,
    mismatches: int = 1,
    batch_size: int = 100000,
    threads: Optional[int] = None,
    verbose: bool = False
) -> None:
    """Optimized sequence extraction focused on matching performance"""
    
    # Initialize configurations
    barcode_positions = pd.read_csv(barcode_positions_file)
    barcode_configs = prepare_barcode_configs(barcode_positions, jitter)
    parsed_range = parse_range(read1_range) if read1_range else parse_range(read2_range)
    read_index = 0 if read1_range else 1

    # Create optimized matcher
    matcher = BarcodeMatcherOptimized(
        barcode_sequences={k: set(v) for k, v in barcode_sequences.items()},
        mismatches=mismatches
    )
    
    # Use minimal threading for I/O
    threads = min(4, threads or mp.cpu_count())
    
    # Process files with minimal overhead
    with pysam.FastqFile(fastq_files[0]) as r1, \
         pysam.FastqFile(fastq_files[1]) as r2, \
         open(output, 'w') as out_fastq:
        
        # Create batches efficiently
        read_pairs = zip(r1, r2)
        current_batch = []
        
        for reads in read_pairs:            
            current_batch.append(reads)            
            if len(current_batch) >= batch_size:
                entries = process_read_batch(
                    current_batch, barcode_configs, matcher, 
                    parsed_range, read_index, verbose
                )
                out_fastq.writelines(entries)
                current_batch = []
        
        # Process remaining reads
        if current_batch:
            entries = process_read_batch(
                current_batch, barcode_configs, matcher, 
                parsed_range, read_index, verbose
            )
            out_fastq.writelines(entries)

def parse_range(range_str: str) -> Tuple[int, int]:
    """Parse range string"""
    start, end = map(int, range_str.split('-'))
    return (start, end)

def prepare_barcode_configs(positions: pd.DataFrame, jitter: int) -> List[Dict]:
    """Prepare barcode configurations"""
    return [{
        'index': idx,
        'file_index': 0 if row['read'] == 'read1' else 1,
        'start': row['start'],
        'end': row['end'],
        'orientation': row['orientation'],
        'whitelist': row['barcode_whitelist']
    } for idx, row in positions.iterrows()]