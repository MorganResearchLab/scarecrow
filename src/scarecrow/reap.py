# -*- coding: utf-8 -*-
"""
#!/usr/bin/env python3
@author: David Wragg
"""

import os
import gzip
import pandas as pd
import pysam
import multiprocessing as mp
from argparse import RawTextHelpFormatter
import logging
from scarecrow.logger import log_errors, setup_logger
from scarecrow.seed import parse_seed_arguments
from scarecrow.tools import generate_random_string, reverse_complement
from typing import List, Tuple, Optional, Dict, Any, Union
import itertools
from functools import partial
import ast

def parser_reap(parser):
    subparser = parser.add_parser(
        "reap",
        description="""
Extract sequence range from one fastq file of a pair, and annotate the sequence header with barcode 
sequences based on predicted positions generated by scarecrow harvest.

Example:

scarecrow reap R1.fastq.gz R2.fastq.gz\n\t--barcode_positions barcode_positions.csv\n\t--barcodes BC1:bc1_whitelist.txt BC2:bc2_whitelist.txt BC3:bc3_whitelist.txt\n\t--read2 0-100 --out cdna.fastq
---
""",
        epilog="The --barcodes <name> must match the barcode_whitelist values in the --barcode_positions file.",
        help="Extract sequence range from fastq files",
        formatter_class=RawTextHelpFormatter,
    )
    subparser.add_argument("fastqs", nargs="+", help="List of FASTQ files")
    subparser.add_argument(
        "-o", "--out",
        metavar="out.fastq",
        help=("Path to output fastq file"),
        type=str,
        default='extracted.fastq',
    )
    subparser.add_argument(
        "-p", "--barcode_positions",
        metavar="barcode_positions",
        help=("File containing barcode positions, output by scarecrow harvest"),
        type=str,
        default=[],
    )
    subparser.add_argument(
        "-j", "--jitter",
        metavar="jitter",
        type=int,
        default=5,
        help='Barcode position jitter [5]',
    )
    subparser.add_argument(
        "-m", "--mismatches",
        metavar="mismatches",
        type=int,
        default=1,
        help='Number of allowed mismatches in barcode [1]',
    )
    group = subparser.add_mutually_exclusive_group(required=True)
    group.add_argument(
        "-1", "--read1",
        metavar="read1_range",
        help=("Sequence range to extract from read1 (e.g. (0-100))"),
        type=str,
        default=None
    )
    group.add_argument(
        "-2", "--read2",
        metavar="read2_range",
        help=("Sequence range to extract from read2 (e.g. 0-100)"),
        type=str,
        default=None
    )
    subparser.add_argument(
        "-c", "--barcodes",
        metavar="barcodes",
        nargs='+', 
        help='Barcode whitelist files in format <name>:<file> (e.g. BC1:barcodes1.txt BC2:barcodes2.txt)',
    )
    subparser.add_argument(
        "-b", "--batch_size",
        metavar="batch_size",
        help=("Number of read pairs per batch to process at a time [10000]"),
        type=int,
        default=10000,
    )
    subparser.add_argument(
        "-@", "--threads",
        metavar="threads",
        help=("Number of processing threads [4]"),
        type=int,
        default=4,
    )
    return subparser

def validate_reap_args(parser, args):
    run_reap(fastqs = [f for f in args.fastqs], 
             barcode_positions = args.barcode_positions,
             output = args.out,
             read1_range = args.read1,
             read2_range = args.read2, 
             barcodes = args.barcodes,
             jitter = args.jitter,
             mismatches = args.mismatches,
             batches = args.batch_size, 
             threads = args.threads)

@log_errors
def run_reap(fastqs: List[str], 
             barcode_positions: str,
             output: str = 'extracted.fastq',
             read1_range: Optional[str] = None,
             read2_range: Optional[str] = None,
             barcodes: List[str] = None,
             jitter: int = 5,
             mismatches: int = 1,
             batches: int = 10000,
             threads: int = 4) -> None:
    """
    Main function to extract sequences with barcode headers
    """    
    # Global logger setup
    logfile = '{}_{}.{}'.format('./scarecrow_reap', generate_random_string(), 'log')
    logger = setup_logger(logfile)

    # Extract barcodes
    expected_barcodes = parse_seed_arguments(barcodes)  
    logger.info(f"Barcode whitelist:")
    for key, barcode in expected_barcodes.items():
        logger.info(f"{key}: {barcode}")

    # Extract barcodes and target sequence
    extract_sequences_parallel(
        fastq_files = [f for f in fastqs],
        barcode_positions_file = barcode_positions,
        barcode_sequences = expected_barcodes,
        output = output,
        read1_range = read1_range,
        read2_range = read2_range,
        jitter = jitter,
        mismatches = mismatches,
        batch_size = batches,
        threads = threads
    )
    

def parse_range(range_str: str) -> Tuple[int, int]:
    """Parse string range like '0-100' into start and end integers"""
    start, end = map(int, range_str.split('-'))
    return (start, end)

def prepare_barcode_configs(barcode_positions: pd.DataFrame, jitter: int) -> List[Dict[str, Any]]:
    """Prepare barcode extraction configurations"""
    configs = []
    for idx, row in barcode_positions.iterrows():
        config = {
            'index': idx,
            'file_index': 0 if row['read'] == 'read1' else 1,
            'start': row['start'],
            'end': row['end'],
            'orientation': row['orientation'],
            'jittered_start': max(0, row['start'] - jitter),
            'jittered_end': row['end'] + jitter,
            'whitelist': row['barcode_whitelist']
        }
        configs.append(config)
    return configs

@log_errors
def extract_sequences_parallel(
    fastq_files: List[str],
    barcode_positions_file: str,
    barcode_sequences: Optional[Union[Dict[str, List[str]], List[str]]] = None,
    output: str = 'extracted.fastq',
    read1_range: Optional[str] = None,
    read2_range: Optional[str] = None,
    jitter: int = 5,
    mismatches: int = 1,
    batch_size: int = 100000,
    threads: int = None
) -> None:
    """
    Extract sequences to FASTQ with modified headers using parallel processing
    """
    # Setup logging
    logfile = '{}_{}.{}'.format('./scarecrow_reap_barcodes', generate_random_string(), 'log')
    logger = setup_logger(logfile)


    # Read and parse barcode positions
    barcode_positions = pd.read_csv(barcode_positions_file)
    logger.info(f"{barcode_positions}")

    # Parse read ranges
    parsed_read1_range = parse_range(read1_range) if read1_range else None
    parsed_read2_range = parse_range(read2_range) if read2_range else None

    # Prepare barcode configurations
    barcode_configs = prepare_barcode_configs(barcode_positions, jitter)

    # Set up parallel processing
    threads = threads or (mp.cpu_count() - 1 or 1)

    # Ensure output directory exists
    os.makedirs(os.path.dirname(output) or '.', exist_ok=True)

    # Process files
    read1, read2 = fastq_files
    out_mode = 'wt' if not output.endswith('.gz') else 'wt'
    open_func = gzip.open if output.endswith('.gz') else open

    with pysam.FastqFile(read1) as r1, \
         pysam.FastqFile(read2) as r2, \
         open_func(output, out_mode) as out_fastq:

        # Create read pair iterator
        read_pairs = zip(r1, r2)

        # Prepare partial function for multiprocessing
        process_batch_func = partial(
            process_read_batch,
            barcode_configs = barcode_configs,
            barcode_sequences = barcode_sequences,
            mismatches = mismatches,
            read1_range = parsed_read1_range,
            read2_range = parsed_read2_range,
            logfile = logfile
        )

        # Process in batches with multiprocessing
        with mp.Pool(processes=threads) as pool:
            # Create batches of reads
            batch_iterator = iter(lambda: list(itertools.islice(read_pairs, batch_size)), [])

            for batch in batch_iterator:
                if not batch:
                    break

                # Process batch in parallel
                processed_entries = pool.map(process_batch_func, [batch])

                # Flatten and write results
                for entry in itertools.chain.from_iterable(processed_entries):
                    out_fastq.write(entry)

@log_errors
def match_barcode(sequence, barcodes, orientation, max_mismatches, jitter):
    """
    Find all positions of barcodes in a sequence with tolerance for mismatches.
    """
    logger = logging.getLogger('scarecrow')

    def hamming_distance(s1, s2):
        """Calculate Hamming distance between two strings."""
        return sum(c1 != c2 for c1, c2 in zip(s1, s2))
    
    barcode_matches = []
    
    for start in range(len(sequence)):
        for barcode in barcodes:
            if orientation == 'reverse':
                barcode = reverse_complement(barcode)
            for end in range(start + len(barcode), len(sequence) + 1):
                candidate = sequence[start:end]
                
                if len(candidate) == len(barcode):
                    mismatches = hamming_distance(candidate, barcode)
                    if mismatches <= max_mismatches:
                        match_details = {
                            'barcode': barcode,
                            'sequence': candidate,
                            'start': start,
                            'end': end,
                            'mismatches': mismatches,
                            'peak_dist': abs(jitter-start)
                        }
                        barcode_matches.append(match_details)
                        logger.info(f"{match_details}")
    
    barcode_matches.sort(key=lambda x: (x['peak_dist'], x['mismatches'], x['start']))
    return barcode_matches

@log_errors   
def process_read_batch(
    read_batch: List[Tuple[Any, Any]], 
    barcode_configs: List[Dict[str, Any]], 
    barcode_sequences: Optional[Union[Dict[str, List[str]], List[str]]],
    read1_range: Optional[Tuple[int, int]], 
    read2_range: Optional[Tuple[int, int]],
    mismatches: int = 1,
    logfile: str = None
) -> List[str]:
    """
    Process a batch of reads, extracting barcodes and sequences
    
    Args:
        read_batch: List of tuples containing (read1, read2) entries
        barcode_configs: Configurations for barcode extraction
        read1_range: Range to extract from read1 if applicable
        read2_range: Range to extract from read2 if applicable
    
    Returns:
        List of formatted FASTQ entries
    """
    if logfile:
        logger = setup_logger(logfile)
    else:
        logger = logging.getLogger('scarecrow')

    output_entries = []
    for r1_entry, r2_entry in read_batch:
        # Extract barcodes
        barcodes = []
        for config in barcode_configs:
            seq = r1_entry.sequence if config['file_index'] == 0 else r2_entry.sequence
            barcode = seq[config['jittered_start']:config['jittered_end']]
            barcodes.append(barcode)
            
            # Identify associated whitelist barcode sequences
            whitelist = ast.literal_eval(config['whitelist'])[0]
            if whitelist in barcode_sequences:
                whitelist_barcodes = barcode_sequences[whitelist]                
                orientation = False if config['orientation'] == 'forward' else True                
                matches = match_barcode(sequence = barcode, barcodes = whitelist_barcodes, 
                                    orientation = orientation, max_mismatches = mismatches,
                                    jitter = abs(config['jittered_start'] - config['start']))
                if matches:
                    logger.info(f"{r1_entry.name}")
                    logger.info(f"{seq}")
                    logger.info(f"Peak target:\n{list(config.items())[2:]}")
                    logger.info(f"Best matched barcode (peak distance, mismatches, start):\n{matches[0]}")
            
            
            
            
        # Determine which read to extract from
        if read1_range:
            extract_seq = r1_entry.sequence[read1_range[0]:read1_range[1]]
            extract_qual = r1_entry.quality[read1_range[0]:read1_range[1]]
            source_entry = r1_entry
        else:
            extract_seq = r2_entry.sequence[read2_range[0]:read2_range[1]]
            extract_qual = r2_entry.quality[read2_range[0]:read2_range[1]]
            source_entry = r2_entry
        
        # Modify header with barcodes
        new_header = f"{source_entry.name}_{('_').join(barcodes)}"
        
        # Create FASTQ entry
        output_entries.append(f"@{new_header}\n{extract_seq}\n+\n{extract_qual}\n")
    
    return output_entries
